{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(data, window_size=96):\n",
    "    \"\"\"\n",
    "    Separa o vetor data em pares de vetores X de entrada e valor de predição y\n",
    "    data: Conjunto de dados\n",
    "    window_size: Tamanho dos vetores de dados em X\n",
    "    Retorna o vetor X e Y\n",
    "    \"\"\"\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    len_data = len(data)\n",
    "    for i in range(len_data - window_size):\n",
    "        data_X.append(data[i:i + window_size])\n",
    "        data_Y.append(data[i + window_size])\n",
    "    return np.array(data_X), np.array(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "from segmentation_algorithms.utils import *\n",
    "\n",
    "from time import perf_counter \n",
    "\n",
    "try:\n",
    "  importlib.reload(plot)\n",
    "except:\n",
    "  import plot\n",
    "  importlib.reload(plot)\n",
    "from plot import plot\n",
    "\n",
    "try:\n",
    "  importlib.reload(segmentation_algorithms.topdown_index)\n",
    "except:\n",
    "  import segmentation_algorithms.topdown_index\n",
    "  importlib.reload(segmentation_algorithms.topdown_index)\n",
    "from segmentation_algorithms.topdown_index import XTSTreeTopDownIndex\n",
    "\n",
    "try:\n",
    "  importlib.reload(segmentation_algorithms.topdown_reg)\n",
    "except:\n",
    "  import segmentation_algorithms.topdown_reg\n",
    "  importlib.reload(segmentation_algorithms.topdown_reg)\n",
    "from segmentation_algorithms.topdown_reg import XTSTreeTopDownReg\n",
    "\n",
    "try:\n",
    "  importlib.reload(XTSTree.XTSTreePageHinkley)\n",
    "except:\n",
    "  import XTSTree.XTSTreePageHinkley\n",
    "  importlib.reload(XTSTree.XTSTreePageHinkley)\n",
    "from XTSTree.XTSTreePageHinkley import XTSTreePageHinkley\n",
    "\n",
    "try:\n",
    "  importlib.reload(XTSTree.XTSTreeRandomCut)\n",
    "except:\n",
    "  import XTSTree.XTSTreeRandomCut\n",
    "  importlib.reload(XTSTree.XTSTreeRandomCut)\n",
    "from XTSTree.XTSTreeRandomCut import XTSTreeRandomCut\n",
    "\n",
    "try:\n",
    "  importlib.reload(XTSTree.XTSTreePeriodicCut)\n",
    "except:\n",
    "  import XTSTree.XTSTreePeriodicCut\n",
    "  importlib.reload(XTSTree.XTSTreePeriodicCut)\n",
    "from XTSTree.XTSTreePeriodicCut import XTSTreePeriodicCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y, y_hat):\n",
    "    return np.mean(np.abs(y - y_hat))\n",
    "def rmse(y, y_hat):\n",
    "    return np.sqrt(np.mean(np.square(y - y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = np.array(pd.read_csv('./datasets/base datasets/23025122/export_automaticas_23025122_tempmedar2m.csv')['tempmedar2m'][:96*20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page-Hinkley aplicado na série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não achei só um corte, escolhendo corte que gera maior pontuação, 1634, 683.5525588636692, 0, 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.8408824328772228, 12, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = perf_counter()\n",
    "ph_model = XTSTreePageHinkley(stop_condition='adf', stop_val=0.5, max_iter=100, min_dist=0)\n",
    "ph_model = ph_model.create_splits(series)\n",
    "# plot(np.array(series), divisions=ph_model.cut_points(), title=f'Tempo: {perf_counter() - t}')\n",
    "segments_page_hinkley = ph_model.cut_series(series)\n",
    "ph_model.calculate_entropy_gain()\n",
    "ph_model.calc_mean_entropy_gain_by_cut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9711242889269724, 13, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = perf_counter()\n",
    "ran_model = XTSTreeRandomCut(stop_condition='adf', stop_val=0, max_iter=100, min_dist=0)\n",
    "ran_model = ran_model.create_splits(series)\n",
    "# plot(np.array(series), divisions=ran_model.cut_points(), title=f'Tempo: {perf_counter() - t}')\n",
    "segments_random = ran_model.cut_series(series)\n",
    "ran_model.calculate_entropy_gain()\n",
    "ran_model.calc_mean_entropy_gain_by_cut()\n",
    "# for depth, val in ran_model.get_items_by_depth().items():\n",
    "#   print(f'Profundidade: {depth}')\n",
    "#   for content in val:\n",
    "#     print(f'Posição: {content[\"cut_pos\"]}, entropia: {content[\"entropy\"]}, ganho: {content[\"entropy_gain\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periodic cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.5893157084623921, 8, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = perf_counter()\n",
    "per_model = XTSTreePeriodicCut(stop_condition='adf', stop_val=0, max_iter=100, min_dist=0)\n",
    "per_model = per_model.create_splits(series)\n",
    "# plot(np.array(series), divisions=per_model.cut_points(), title=f'Tempo: {perf_counter() - t}')\n",
    "segments_periodic = per_model.cut_series(series)\n",
    "per_model.calculate_entropy_gain()\n",
    "per_model.calc_mean_entropy_gain_by_cut()\n",
    "# for depth, val in per_model.get_items_by_depth().items():\n",
    "#   print(f'Profundidade: {depth}')\n",
    "#   for content in val:\n",
    "#     print(f'Posição: {content[\"cut_pos\"]}, entropia: {content[\"entropy\"]}, ganho: {content[\"entropy_gain\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão linear aplicado no índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.044270106902216264, 37, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_model, _, _, _ = apply_lr(np.arange(len(series)), series)\n",
    "yhat = m_model.predict(np.arange(len(series)).reshape(-1, 1))\n",
    "error = rmse(series, yhat)\n",
    "# plot(series, sec_plots=[yhat], title=f'error: {error}')\n",
    "\n",
    "t = perf_counter()\n",
    "tdi_model = XTSTreeTopDownIndex(stop_val=2.5, max_iter=100, min_dist=0)\n",
    "tdi_model = tdi_model.create_splits(series)\n",
    "# plot(series, divisions=tdi_model.cut_points(), title=f'Tempo: {perf_counter() - t}')\n",
    "segments_tdi = tdi_model.cut_series(series)\n",
    "tdi_model.calculate_entropy_gain()\n",
    "tdi_model.calc_mean_entropy_gain_by_cut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressão linear aplicado numa janela variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0053873094308409175, 95, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag = 2\n",
    "\n",
    "X, y = group_data(series, lag)\n",
    "m_model, _, _, _ = apply_lr(X, y)\n",
    "yhat = m_model.predict(X)\n",
    "error = rmse(series[lag:], yhat)\n",
    "# plot(series[lag:], sec_plots=[yhat], title=f'error: {error}')\n",
    "\n",
    "t = perf_counter()\n",
    "tdr_model = XTSTreeTopDownReg(stop_val=0.3, max_iter=100, min_dist=0, lag=lag)\n",
    "tdr_model = tdr_model.create_splits(series)\n",
    "# plot(series, divisions=tdr_model.cut_points(), title=f'Tempo: {perf_counter() - t}')\n",
    "segments_tdr = tdr_model.cut_series(series)\n",
    "tdr_model.calculate_entropy_gain()\n",
    "tdr_model.calc_mean_entropy_gain_by_cut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr import *\n",
    "def get_regressor(\n",
    "    criteria,\n",
    "    output_file,\n",
    "    pop_n,\n",
    "    pop_size,\n",
    "    iterations,\n",
    "    max_complexity=20,\n",
    "    binary_operators=['+', '-', '*', '/', 'pow'],\n",
    "    unary_operators=['sqrt', 'sin'],\n",
    "    constraints=None,\n",
    "    verbosity=0,\n",
    "    early_stop_condition=None\n",
    "   ):\n",
    "  \"\"\"\n",
    "  constraints é um dicionário com os operadores unários e binários e uma tupla com a complexidade máxima dos argumentos.\n",
    "  ver o que o should_simplify faz, aparentemente simplifica a equação, mas ver como ele faz isso\n",
    "  usar random_state pra garantir mesmos resultados\n",
    "  \"\"\"\n",
    "  return PySRRegressor(\n",
    "    binary_operators=binary_operators,\n",
    "    unary_operators=unary_operators,\n",
    "    maxsize=max_complexity,\n",
    "    niterations=iterations,\n",
    "    populations=pop_n,\n",
    "    population_size=pop_size,\n",
    "    progress=False,\n",
    "    model_selection=criteria,\n",
    "    equation_file=f'./symbreg_objects/{output_file}.csv',\n",
    "    verbosity = verbosity,\n",
    "    temp_equation_file=False,\n",
    "    early_stop_condition=early_stop_condition\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria='best'\n",
    "pop_n=10\n",
    "pop_size=40\n",
    "iterations=100\n",
    "max_complexity=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro no PySR durante a execução nos segmentos\n",
      "Tamanho do segmento: 4\n",
      "Equação: (sin(sqrt(sqrt(sqrt(0.6954404 * x0) ^ ((((((-30.06074 * x0) - 0.16878094) + sqrt(x0 * x0)) - sqrt(sin(sqrt(x0 / (((x0 + x0) + x0) ^ x0))) * sin(x0))) * sin(x0)) - x0)))) - -30.008398)\n",
      "Erro: Failed to evaluate the expression. If you are using a custom operator, make sure to define it in `extra_sympy_mappings`, e.g., `model.set_params(extra_sympy_mappings={'inv': lambda x: 1/x})`, where `lambda x: 1/x` is a valid SymPy function defining the operator. You can then run `model.refresh()` to re-load the expressions.\n",
      "Erro no PySR durante a execução nos segmentos\n",
      "Tamanho do segmento: 5\n",
      "Equação: ((25.741693 + sin((sin(x0) + 0.4214384) / ((sqrt(x0) - sin(-0.9029002)) - -1.9523088))) + ((sin(((sin(((-0.25420377 - 0.25849393) ^ x0) ^ x0) + -0.15308075) / (x0 ^ x0)) + x0) / 1.1894562) * 1.1141248))\n",
      "Erro: Failed to evaluate the expression. If you are using a custom operator, make sure to define it in `extra_sympy_mappings`, e.g., `model.set_params(extra_sympy_mappings={'inv': lambda x: 1/x})`, where `lambda x: 1/x` is a valid SymPy function defining the operator. You can then run `model.refresh()` to re-load the expressions.\n",
      "Erro no PySR durante a execução nos segmentos\n",
      "Tamanho do segmento: 27\n",
      "Equação: ((19.566435 + (((x0 ^ sin(x0)) - -1.5926858) / (x0 ^ x0))) - sin(0.16486216 * (x0 + (sin((x0 ^ 0.021237476) ^ (x0 - -0.6844165)) / 0.34431002))))\n",
      "Erro: Failed to evaluate the expression. If you are using a custom operator, make sure to define it in `extra_sympy_mappings`, e.g., `model.set_params(extra_sympy_mappings={'inv': lambda x: 1/x})`, where `lambda x: 1/x` is a valid SymPy function defining the operator. You can then run `model.refresh()` to re-load the expressions.\n",
      "Erro no PySR durante a execução nos segmentos\n",
      "Tamanho do segmento: 4\n",
      "Equação: (((1.093087 ^ x0) - ((sqrt(0.53035486 ^ (x0 - 0.049128775)) ^ x0) / (x0 ^ x0))) - -20.687567)\n",
      "Erro: Failed to evaluate the expression. If you are using a custom operator, make sure to define it in `extra_sympy_mappings`, e.g., `model.set_params(extra_sympy_mappings={'inv': lambda x: 1/x})`, where `lambda x: 1/x` is a valid SymPy function defining the operator. You can then run `model.refresh()` to re-load the expressions.\n",
      "Erro no PySR durante a execução nos segmentos\n",
      "Tamanho do segmento: 13\n",
      "Equação: ((((sin(x0 * -0.30414188) / 0.25648478) - (1.660604 / -0.05621096)) + sin(sin(((x0 + 1.1748463) + 0.25648478) - sin(x0 * 0.9474994)))) + (1.6606579 / (x0 ^ x0)))\n",
      "Erro: Failed to evaluate the expression. If you are using a custom operator, make sure to define it in `extra_sympy_mappings`, e.g., `model.set_params(extra_sympy_mappings={'inv': lambda x: 1/x})`, where `lambda x: 1/x` is a valid SymPy function defining the operator. You can then run `model.refresh()` to re-load the expressions.\n",
      "Erro no PySR durante a execução nos segmentos\n",
      "Tamanho do segmento: 14\n",
      "Equação: (((((((((sqrt(sqrt(0.027785124) / 0.65297174) ^ sin((sqrt(x0) / (x0 ^ x0)) - ((10.702031 - x0) / 1.1860911))) ^ x0) * x0) - -1.8361785) ^ sin(sin(-1.0436246))) + 11.839101) / sqrt(0.65780747)) + 10.702031) - (sin(((sin(1.3515663 + (0.59200716 - x0)) / (x0 - 1.1865461)) - ((0.1370117 ^ ((sqrt(sqrt(x0)) - sqrt(1.1860911)) - sin(x0))) * x0)) / -13.235685) + sqrt(sin(0.022668235 ^ 1.1397297))))\n",
      "Erro: Failed to evaluate the expression. If you are using a custom operator, make sure to define it in `extra_sympy_mappings`, e.g., `model.set_params(extra_sympy_mappings={'inv': lambda x: 1/x})`, where `lambda x: 1/x` is a valid SymPy function defining the operator. You can then run `model.refresh()` to re-load the expressions.\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for rep in range(10):\n",
    "  modelo = get_regressor(\n",
    "    criteria=criteria,\n",
    "    output_file='teste',\n",
    "    pop_n=pop_n,\n",
    "    pop_size=pop_size,\n",
    "    iterations=iterations,\n",
    "    max_complexity=max_complexity,\n",
    "  )\n",
    "  t = perf_counter()\n",
    "  modelo.fit([[i] for i in range(len(series))], series)\n",
    "  end_t = perf_counter() - t\n",
    "\n",
    "  prediction_full = modelo.predict(np.array([[i] for i in range(len(series))]))\n",
    "  complexity_full = modelo.get_best()[\"complexity\"]\n",
    "\n",
    "  output.append({\n",
    "    'nome': f'Full_{rep}',\n",
    "    'MAE (erro entre a série inteira e a predição de todos os segmentos)': mae(series, prediction_full),\n",
    "    'RMSE (erro entre a série inteira e a predição de todos os segmentos)': rmse(series, prediction_full),\n",
    "    'complexidade (média dos segmentos)': complexity_full,\n",
    "    'desvio padrão complexidade': 0,\n",
    "    'criteria': criteria,\n",
    "    'pop_n': pop_n,\n",
    "    'pop_size': pop_size,\n",
    "    'iterations': iterations,\n",
    "    'max_complexity': max_complexity,\n",
    "    'tempo': end_t,\n",
    "    'numero de segmentos': 1,\n",
    "  })\n",
    "  pd.DataFrame(output).to_csv('./resultados.csv', index=False)\n",
    "  for segments, name in [(segments_page_hinkley, 'Page-hinkley'), (segments_periodic, 'Periodic'), (segments_random, 'Random'), (segments_tdi, 'Top-down index'), (segments_tdr, 'Top-down regression')]:\n",
    "    y_hat = []\n",
    "    complexities = []\n",
    "    try:\n",
    "      time = perf_counter()\n",
    "      for segment in segments:\n",
    "        modelo = get_regressor(\n",
    "          criteria=criteria,\n",
    "          output_file='teste',\n",
    "          pop_n=pop_n,\n",
    "          pop_size=pop_size,\n",
    "          iterations=iterations,\n",
    "          max_complexity=max_complexity,\n",
    "        )\n",
    "        modelo.fit([[i] for i in range(len(segment))], segment)\n",
    "\n",
    "        prediction = modelo.predict(np.array([[i] for i in range(len(segment))]))\n",
    "        y_hat = y_hat + list(prediction)\n",
    "        complexities.append(modelo.get_best()[\"complexity\"])\n",
    "      end_t = perf_counter() - time\n",
    "      output.append({\n",
    "        'nome': f'{name}_{rep}',\n",
    "        'MAE (erro entre a série inteira e a predição de todos os segmentos)': mae(series, y_hat),\n",
    "        'RMSE (erro entre a série inteira e a predição de todos os segmentos)': rmse(series, y_hat),\n",
    "        'complexidade (média dos segmentos)': np.mean(complexities),\n",
    "        'desvio padrão complexidade': np.std(complexities),\n",
    "        'criteria': criteria,\n",
    "        'pop_n': pop_n,\n",
    "        'pop_size': pop_size,\n",
    "        'iterations': iterations,\n",
    "        'max_complexity': max_complexity,\n",
    "        'tempo': end_t,\n",
    "        'numero de segmentos': len(segments),\n",
    "      })\n",
    "      pd.DataFrame(output).to_csv('./resultados.csv', index=False)\n",
    "    except Exception as e:\n",
    "      print(f'Erro no PySR durante a execução nos segmentos')\n",
    "      print(f'Tamanho do segmento: {len(segment)}')\n",
    "      print(f'Equação: {modelo.get_best()[\"equation\"]}')\n",
    "      print(f'Erro: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>MAE (erro entre a série inteira e a predição de todos os segmentos)</th>\n",
       "      <th>RMSE (erro entre a série inteira e a predição de todos os segmentos)</th>\n",
       "      <th>complexidade (média dos segmentos)</th>\n",
       "      <th>desvio padrão complexidade</th>\n",
       "      <th>criteria</th>\n",
       "      <th>pop_n</th>\n",
       "      <th>pop_size</th>\n",
       "      <th>iterations</th>\n",
       "      <th>max_complexity</th>\n",
       "      <th>tempo</th>\n",
       "      <th>numero de segmentos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full_0</td>\n",
       "      <td>2.311779</td>\n",
       "      <td>2.830528</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>19.741255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Page-hinkley_0</td>\n",
       "      <td>1.232133</td>\n",
       "      <td>1.723117</td>\n",
       "      <td>26.307692</td>\n",
       "      <td>3.122736</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.318036</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top-down index_0</td>\n",
       "      <td>1.108671</td>\n",
       "      <td>1.529832</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>10.530032</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>82.472898</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nome  \\\n",
       "0            Full_0   \n",
       "1    Page-hinkley_0   \n",
       "2  Top-down index_0   \n",
       "\n",
       "   MAE (erro entre a série inteira e a predição de todos os segmentos)  \\\n",
       "0                                           2.311779                     \n",
       "1                                           1.232133                     \n",
       "2                                           1.108671                     \n",
       "\n",
       "   RMSE (erro entre a série inteira e a predição de todos os segmentos)  \\\n",
       "0                                           2.830528                      \n",
       "1                                           1.723117                      \n",
       "2                                           1.529832                      \n",
       "\n",
       "   complexidade (média dos segmentos)  desvio padrão complexidade  criteria  \\\n",
       "0                           29.000000                    0.000000  accuracy   \n",
       "1                           26.307692                    3.122736  accuracy   \n",
       "2                           12.500000                   10.530032  accuracy   \n",
       "\n",
       "   pop_n  pop_size  iterations  max_complexity      tempo  numero de segmentos  \n",
       "0      5        20          30              30  19.741255                    1  \n",
       "1      5        20          30              30  30.318036                   13  \n",
       "2      5        20          30              30  82.472898                   38  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = pd.read_csv('resultados.csv')\n",
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
